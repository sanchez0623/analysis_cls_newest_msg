"""
CLS Telegraph Scraper with anti-scraping measures.

This module handles fetching news from the CLS Telegraph API with:
- Signature generation for API authentication
- Request retrying with exponential backoff
- Random user agent rotation
- Proper error handling
"""

import hashlib
import logging
import random
import time
from typing import List, Optional

import requests
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)

from .config import config
from .models import NewsItem


logger = logging.getLogger(__name__)


# User agents pool for rotation
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15",
]


class CLSScraper:
    """
    Scraper for CLS Telegraph news with robust anti-scraping handling.
    
    Features:
    - API signature generation
    - Request retrying with exponential backoff
    - User agent rotation
    - Session management for connection pooling
    - Duplicate detection
    """
    
    def __init__(self):
        """Initialize the scraper."""
        self._session = requests.Session()
        self._last_news_id: Optional[str] = None
        self._setup_session()
    
    def _setup_session(self) -> None:
        """Set up the requests session with default headers."""
        self._session.headers.update({
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Referer": "https://www.cls.cn/telegraph",
            "Origin": "https://www.cls.cn",
            "Connection": "keep-alive",
        })
    
    def _get_random_user_agent(self) -> str:
        """Get a random user agent from the pool."""
        return random.choice(USER_AGENTS)
    
    @staticmethod
    def _generate_sign(params_str: str) -> str:
        """
        Generate the API signature.
        
        The CLS API requires a signature generated by:
        1. SHA1 hash of the parameter string
        2. MD5 hash of the SHA1 result
        
        Args:
            params_str: The parameter string to sign
            
        Returns:
            The hexadecimal signature string
        """
        sha1_hash = hashlib.sha1(params_str.encode("utf-8")).hexdigest()
        md5_hash = hashlib.md5(sha1_hash.encode("utf-8")).hexdigest()
        return md5_hash
    
    def _build_api_url(self, last_time: Optional[int] = None) -> str:
        """
        Build the API URL with proper parameters and signature.
        
        Args:
            last_time: Unix timestamp for pagination (optional)
            
        Returns:
            The complete API URL with signature
        """
        if last_time is None:
            last_time = int(time.time())
        
        # Build parameter string (order matters for signature)
        params = {
            "app": config.cls_app,
            "last_time": last_time,
            "os": config.cls_os,
            "rn": config.fetch_count,
            "sv": config.cls_sv,
        }
        
        # Create parameter string for signature
        params_str = "&".join(f"{k}={v}" for k, v in sorted(params.items()))
        
        # Generate signature
        sign = self._generate_sign(params_str)
        
        # Build complete URL
        url = f"{config.cls_api_url}?{params_str}&sign={sign}"
        return url
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10),
        retry=retry_if_exception_type((requests.RequestException, ConnectionError)),
    )
    def _make_request(self, url: str) -> dict:
        """
        Make an HTTP request with retry logic.
        
        Args:
            url: The URL to fetch
            
        Returns:
            The JSON response as a dictionary
            
        Raises:
            requests.RequestException: If the request fails after retries
        """
        self._session.headers["User-Agent"] = self._get_random_user_agent()
        
        logger.debug(f"Fetching URL: {url}")
        
        response = self._session.get(
            url,
            timeout=config.request_timeout,
        )
        response.raise_for_status()
        
        return response.json()
    
    def fetch_latest_news(self) -> Optional[NewsItem]:
        """
        Fetch the latest news item from CLS Telegraph.
        
        Returns:
            The latest NewsItem if new, None if same as last fetch or error
        """
        try:
            url = self._build_api_url()
            data = self._make_request(url)
            
            # Parse response
            if data.get("errno") != 0:
                logger.error(f"API returned error: {data.get('errmsg', 'Unknown error')}")
                return None
            
            news_list = data.get("data", {}).get("roll_data", [])
            
            if not news_list:
                logger.warning("No news items returned from API")
                return None
            
            # Get the latest news item
            latest = news_list[0]
            news_item = NewsItem.from_api_response(latest)
            
            # Check for duplicates
            if news_item.id == self._last_news_id:
                logger.debug(f"Duplicate news item detected: {news_item.id}")
                return None
            
            # Update last seen ID
            self._last_news_id = news_item.id
            
            logger.info(f"Fetched new news: {news_item}")
            return news_item
            
        except requests.RequestException as e:
            logger.error(f"Request failed: {e}")
            return None
        except (KeyError, IndexError, ValueError) as e:
            logger.error(f"Failed to parse API response: {e}")
            return None
    
    def fetch_multiple_news(self, count: int = 20) -> List[NewsItem]:
        """
        Fetch multiple news items.
        
        Args:
            count: Number of items to fetch
            
        Returns:
            List of NewsItem objects
        """
        # Temporarily set fetch count
        original_count = config.fetch_count
        
        try:
            url = self._build_api_url()
            # Modify URL to fetch more items
            url = url.replace(f"rn={original_count}", f"rn={count}")
            
            data = self._make_request(url)
            
            if data.get("errno") != 0:
                logger.error(f"API returned error: {data.get('errmsg', 'Unknown error')}")
                return []
            
            news_list = data.get("data", {}).get("roll_data", [])
            
            return [NewsItem.from_api_response(item) for item in news_list]
            
        except Exception as e:
            logger.error(f"Failed to fetch multiple news: {e}")
            return []
    
    def close(self) -> None:
        """Close the session."""
        self._session.close()
    
    def __enter__(self):
        """Context manager entry."""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit."""
        self.close()
